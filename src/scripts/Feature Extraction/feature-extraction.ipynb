{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ## Step 2: Feature Extraction (with Jitter & Shimmer)\n",
    "#\n",
    "# This step takes the preprocessed audio files from Step 1, extracts various acoustic features using `librosa` and `parselmouth-praat`, and saves them into compressed `.npz` files. It includes caching and multiprocessing.\n",
    "#\n",
    "# **Features Extracted:**\n",
    "# - **Librosa (Frame-wise):**\n",
    "#   - Mel-Frequency Cepstral Coefficients (MFCCs)\n",
    "#   - Root Mean Square Energy (RMS)\n",
    "#   - Spectral Centroid\n",
    "#   - Spectral Bandwidth\n",
    "#   - Spectral Contrast\n",
    "#   - Spectral Flatness\n",
    "#   - Spectral Rolloff\n",
    "#   - Pitch (Fundamental Frequency - F0 using PYIN)\n",
    "#   - Zero-Crossing Rate (ZCR)\n",
    "# - **Parselmouth/Praat (Scalar per file):**\n",
    "#   - Pitch (Praat's algorithm - Median F0)\n",
    "#   - Jitter (local, local_absolute, rap, ppq5)\n",
    "#   - Shimmer (local, local_db, apq3, apq5, apq11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:34:24.826696Z",
     "iopub.status.busy": "2025-04-23T15:34:24.826390Z",
     "iopub.status.idle": "2025-04-23T15:34:24.967560Z",
     "shell.execute_reply": "2025-04-23T15:34:24.966803Z",
     "shell.execute_reply.started": "2025-04-23T15:34:24.826671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import librosa\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from multiprocessing import Pool, cpu_count, Manager, Value\n",
    "import traceback  # For detailed error logging\n",
    "import warnings  # To suppress specific warnings if needed\n",
    "import gc  # For garbage collection\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:34:26.810046Z",
     "iopub.status.busy": "2025-04-23T15:34:26.809754Z",
     "iopub.status.idle": "2025-04-23T15:34:26.814605Z",
     "shell.execute_reply": "2025-04-23T15:34:26.813563Z",
     "shell.execute_reply.started": "2025-04-23T15:34:26.810026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"librosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:34:28.901556Z",
     "iopub.status.busy": "2025-04-23T15:34:28.900855Z",
     "iopub.status.idle": "2025-04-23T15:34:29.189892Z",
     "shell.execute_reply": "2025-04-23T15:34:29.189237Z",
     "shell.execute_reply.started": "2025-04-23T15:34:28.901528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Consider moving these to a config file for easier management\n",
    "# PREPROCESSED_FOLDER = \"./data/\"\n",
    "PREPROCESSED_FOLDER = \"..\\\\..\\\\..\\\\data\\\\preprocessed_sample\\\\\"\n",
    "FEATURE_FOLDER = \"..\\\\..\\\\..\\\\data\\\\features\\\\\"  # Output for Step 2\n",
    "\n",
    "SR = 22050  # Target Sample Rate for librosa features\n",
    "N_FFT = 2048  # FFT window size\n",
    "HOP_LENGTH = 256  # Hop length for STFT\n",
    "N_MELS = 96  # Number of Mel bands\n",
    "N_MFCC = 13  # Number of MFCCs\n",
    "FMIN_PITCH_LIBROSA = librosa.note_to_hz(\"A1\")  # Min frequency for librosa pitch\n",
    "FMAX_PITCH_LIBROSA = librosa.note_to_hz(\"A7\")  # Max frequency for librosa pitch\n",
    "\n",
    "# Praat Pitch Parameters\n",
    "PRAAT_PITCH_FLOOR = 50.0  # Pitch floor (Hz) for Praat analysis\n",
    "PRAAT_PITCH_CEILING = 800.0  # Pitch ceiling (Hz) for Praat analysis\n",
    "\n",
    "# Processing parameters\n",
    "MAX_WORKERS = max(1, cpu_count() - 2)  # Leave one core free\n",
    "PRINT_INTERVAL = 5  # Print progress update every X seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:34:30.771751Z",
     "iopub.status.busy": "2025-04-23T15:34:30.770911Z",
     "iopub.status.idle": "2025-04-23T15:34:30.776740Z",
     "shell.execute_reply": "2025-04-23T15:34:30.775696Z",
     "shell.execute_reply.started": "2025-04-23T15:34:30.771718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)  # Adjust as needed\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\"[%(levelname)s] %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TimeTracker:\n",
    "    \"\"\"Class to track processing time and provide estimates\"\"\"\n",
    "\n",
    "    def __init__(self, total_files):\n",
    "        self.start_time = time.time()\n",
    "        self.total_files = total_files\n",
    "        self.completed = 0\n",
    "        self.skipped = 0\n",
    "        self.failed = 0\n",
    "        self.file_times = []  # Store processing times for better estimates\n",
    "        self.last_print_time = time.time()\n",
    "\n",
    "    def update(self, status, processing_time=None):\n",
    "        \"\"\"Update tracker with a new file status\"\"\"\n",
    "        if status == \"completed\":\n",
    "            self.completed += 1\n",
    "            if processing_time:\n",
    "                self.file_times.append(processing_time)\n",
    "        elif status == \"skipped\":\n",
    "            self.skipped += 1\n",
    "        elif status == \"failed\":\n",
    "            self.failed += 1\n",
    "\n",
    "    def get_progress_str(self):\n",
    "        \"\"\"Get a formatted progress string with ETA\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        total_processed = self.completed + self.skipped + self.failed\n",
    "        progress = total_processed / self.total_files if self.total_files > 0 else 0\n",
    "\n",
    "        # Calculate ETA based on average of recent processing times\n",
    "        if len(self.file_times) > 0 and self.completed > 0:\n",
    "            # Use up to the last 10 files for a more accurate recent average\n",
    "            recent_times = self.file_times[-min(10, len(self.file_times)) :]\n",
    "            avg_time_per_file = sum(recent_times) / len(recent_times)\n",
    "            files_remaining = self.total_files - total_processed\n",
    "            eta_seconds = avg_time_per_file * files_remaining\n",
    "        else:\n",
    "            # Fall back to simple estimation if we don't have timing data\n",
    "            if progress > 0 and elapsed > 0:\n",
    "                eta_seconds = (elapsed / progress) - elapsed\n",
    "            else:\n",
    "                eta_seconds = 0\n",
    "\n",
    "        # Format ETA string\n",
    "        if eta_seconds > 0:\n",
    "            eta_td = timedelta(seconds=int(eta_seconds))\n",
    "            if eta_td.days > 0:\n",
    "                eta_str = (\n",
    "                    f\"{eta_td.days}d {eta_td.seconds//3600}h {(eta_td.seconds//60)%60}m\"\n",
    "                )\n",
    "            elif eta_td.seconds > 3600:\n",
    "                eta_str = f\"{eta_td.seconds//3600}h {(eta_td.seconds//60)%60}m {eta_td.seconds%60}s\"\n",
    "            elif eta_td.seconds > 60:\n",
    "                eta_str = f\"{eta_td.seconds//60}m {eta_td.seconds%60}s\"\n",
    "            else:\n",
    "                eta_str = f\"{eta_td.seconds}s\"\n",
    "        else:\n",
    "            eta_str = \"calculating...\"\n",
    "\n",
    "        # Format elapsed time string\n",
    "        elapsed_td = timedelta(seconds=int(elapsed))\n",
    "        if elapsed_td.days > 0:\n",
    "            elapsed_str = f\"{elapsed_td.days}d {elapsed_td.seconds//3600}h {(elapsed_td.seconds//60)%60}m\"\n",
    "        elif elapsed_td.seconds > 3600:\n",
    "            elapsed_str = f\"{elapsed_td.seconds//3600}h {(elapsed_td.seconds//60)%60}m {elapsed_td.seconds%60}s\"\n",
    "        elif elapsed_td.seconds > 60:\n",
    "            elapsed_str = f\"{elapsed_td.seconds//60}m {elapsed_td.seconds%60}s\"\n",
    "        else:\n",
    "            elapsed_str = f\"{elapsed_td.seconds}s\"\n",
    "\n",
    "        # Build the progress string\n",
    "        progress_str = (\n",
    "            f\"[{total_processed}/{self.total_files}] {progress:.1%} \"\n",
    "            f\"(✅{self.completed} ⏩{self.skipped} ❌{self.failed}) \"\n",
    "            f\"Elapsed: {elapsed_str} | ETA: {eta_str}\"\n",
    "        )\n",
    "\n",
    "        # If we have enough data, add throughput\n",
    "        if elapsed > 60 and self.completed > 0:  # Minimum 1 minute elapsed\n",
    "            files_per_minute = (self.completed / elapsed) * 60\n",
    "            progress_str += f\" | Rate: {files_per_minute:.1f} files/min\"\n",
    "\n",
    "        return progress_str\n",
    "\n",
    "    def should_print_update(self):\n",
    "        \"\"\"Check if we should print a progress update\"\"\"\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_print_time >= PRINT_INTERVAL:\n",
    "            self.last_print_time = current_time\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_final_stats(self):\n",
    "        \"\"\"Get final statistics string\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        elapsed_td = timedelta(seconds=int(elapsed))\n",
    "\n",
    "        # Format elapsed time\n",
    "        if elapsed_td.days > 0:\n",
    "            elapsed_str = f\"{elapsed_td.days}d {elapsed_td.seconds//3600}h {(elapsed_td.seconds//60)%60}m\"\n",
    "        elif elapsed_td.seconds > 3600:\n",
    "            elapsed_str = f\"{elapsed_td.seconds//3600}h {(elapsed_td.seconds//60)%60}m {elapsed_td.seconds%60}s\"\n",
    "        elif elapsed_td.seconds > 60:\n",
    "            elapsed_str = f\"{elapsed_td.seconds//60}m {elapsed_td.seconds%60}s\"\n",
    "        else:\n",
    "            elapsed_str = f\"{elapsed_td.seconds}s\"\n",
    "\n",
    "        # Calculate average time per file\n",
    "        if self.completed > 0:\n",
    "            avg_time = sum(self.file_times) / len(self.file_times)\n",
    "            avg_time_str = f\"{avg_time:.2f}s\"\n",
    "        else:\n",
    "            avg_time_str = \"N/A\"\n",
    "\n",
    "        # Build the stats string\n",
    "        stats = [\n",
    "            f\"Total time: {elapsed_str}\",\n",
    "            f\"Completed:  {self.completed} files\",\n",
    "            f\"Skipped:    {self.skipped} files\",\n",
    "            f\"Failed:     {self.failed} files\",\n",
    "            f\"Total:      {self.total_files} files\",\n",
    "            f\"Avg. time:  {avg_time_str} per file\",\n",
    "        ]\n",
    "\n",
    "        if elapsed > 60 and self.completed > 0:\n",
    "            files_per_minute = (self.completed / elapsed) * 60\n",
    "            stats.append(f\"Throughput:  {files_per_minute:.1f} files/min\")\n",
    "\n",
    "        return \"\\n\".join(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:34:33.917917Z",
     "iopub.status.busy": "2025-04-23T15:34:33.917618Z",
     "iopub.status.idle": "2025-04-23T15:34:33.931123Z",
     "shell.execute_reply": "2025-04-23T15:34:33.929903Z",
     "shell.execute_reply.started": "2025-04-23T15:34:33.917896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_praat_features(\n",
    "    sound, pitch_floor=PRAAT_PITCH_FLOOR, pitch_ceiling=PRAAT_PITCH_CEILING\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts scalar Jitter, Shimmer, and median F0 using Parselmouth/Praat.\n",
    "    \"\"\"\n",
    "    praat_features = {\n",
    "        \"f0_median_praat\": np.nan,\n",
    "        \"jitter_local\": np.nan,\n",
    "        \"jitter_local_abs\": np.nan,\n",
    "        \"jitter_rap\": np.nan,\n",
    "        \"jitter_ppq5\": np.nan,\n",
    "        \"shimmer_local\": np.nan,\n",
    "        \"shimmer_local_db\": np.nan,\n",
    "        \"shimmer_apq3\": np.nan,\n",
    "        \"shimmer_apq5\": np.nan,\n",
    "        \"shimmer_apq11\": np.nan,\n",
    "    }\n",
    "\n",
    "    filename = getattr(sound, \"name\", \"Unknown\")\n",
    "\n",
    "    # Increase minimum duration to ensure robust analysis for diverse voices\n",
    "    if sound.get_total_duration() < 0.2:\n",
    "        logger.warning(f\"⚠️ Sound too short for Praat analysis: {filename}\")\n",
    "        return praat_features\n",
    "\n",
    "    try:\n",
    "        # Use autocorrelation method with adjusted time step for better temporal resolution\n",
    "        pitch = call(\n",
    "            sound,\n",
    "            \"To Pitch (ac)\",\n",
    "            0.01,\n",
    "            pitch_floor,\n",
    "            15,\n",
    "            \"yes\",\n",
    "            0.03,\n",
    "            0.45,\n",
    "            0.01,\n",
    "            0.35,\n",
    "            0.14,\n",
    "            pitch_ceiling,\n",
    "        )\n",
    "\n",
    "        num_frames = call(pitch, \"Get number of frames\")\n",
    "        if num_frames <= 0:\n",
    "            logger.warning(f\"⚠️ No valid pitch frames found in {filename}\")\n",
    "            return praat_features\n",
    "\n",
    "        praat_features[\"f0_median_praat\"] = call(\n",
    "            pitch, \"Get quantile\", 0.0, 0.0, 0.5, \"Hertz\"\n",
    "        )\n",
    "\n",
    "        # Use cross-correlation for point process to improve accuracy\n",
    "        point_process = call(\n",
    "            sound, \"To PointProcess (periodic, cc)\", pitch_floor, pitch_ceiling\n",
    "        )\n",
    "\n",
    "        num_points = call(point_process, \"Get number of points\")\n",
    "        if num_points < 8:  # Stricter threshold for diverse voices\n",
    "            logger.warning(\n",
    "                f\"⚠️ Too few points ({num_points}) for jitter/shimmer analysis in {filename}\"\n",
    "            )\n",
    "            return praat_features\n",
    "\n",
    "        # Adjusted voice report parameters for broader pitch range\n",
    "        report = call(\n",
    "            [sound, point_process, pitch],\n",
    "            \"Voice report\",\n",
    "            0.0,\n",
    "            0.0,\n",
    "            pitch_floor,\n",
    "            pitch_ceiling,\n",
    "            1.5,  # Increased max period factor for low-pitched voices\n",
    "            1.8,  # Increased max amplitude factor for high-pitched voices\n",
    "            0.03,  # Silence threshold\n",
    "            0.45,  # Voicing threshold\n",
    "        )\n",
    "\n",
    "        values = {}\n",
    "        for line in report.strip().split(\"\\n\"):\n",
    "            parts = line.split(\":\")\n",
    "            if len(parts) == 2:\n",
    "                key, val = parts[0].strip(), parts[1].strip().split(\" \")[0]\n",
    "                try:\n",
    "                    values[key] = float(val) if val != \"--undefined--\" else np.nan\n",
    "                except ValueError:\n",
    "                    values[key] = np.nan\n",
    "\n",
    "        mappings = {\n",
    "            \"Jitter (local)\": \"jitter_local\",\n",
    "            \"Jitter (local, absolute)\": \"jitter_local_abs\",\n",
    "            \"Jitter (rap)\": \"jitter_rap\",\n",
    "            \"Jitter (ppq5)\": \"jitter_ppq5\",\n",
    "            \"Shimmer (local)\": \"shimmer_local\",\n",
    "            \"Shimmer (local, dB)\": \"shimmer_local_db\",\n",
    "            \"Shimmer (apq3)\": \"shimmer_apq3\",\n",
    "            \"Shimmer (apq5)\": \"shimmer_apq5\",\n",
    "            \"Shimmer (apq11)\": \"shimmer_apq11\",\n",
    "        }\n",
    "\n",
    "        for praat_key, feature_key in mappings.items():\n",
    "            if praat_key in values:\n",
    "                praat_features[feature_key] = values[praat_key]\n",
    "\n",
    "        # Convert percent-based values\n",
    "        if not np.isnan(praat_features[\"jitter_local\"]):\n",
    "            praat_features[\"jitter_local\"] /= 100.0\n",
    "        if not np.isnan(praat_features[\"shimmer_local\"]):\n",
    "            praat_features[\"shimmer_local\"] /= 100.0\n",
    "\n",
    "        # Adjusted thresholds for diverse voices\n",
    "        for key in [\"jitter_local\", \"jitter_rap\", \"jitter_ppq5\"]:\n",
    "            if (\n",
    "                praat_features.get(key, 0) > 0.15\n",
    "            ):  # Relaxed threshold for elderly/creaky voices\n",
    "                praat_features[key] = np.nan\n",
    "\n",
    "        if (\n",
    "            praat_features[\"shimmer_local\"] > 0.4\n",
    "        ):  # Relaxed threshold for expressive voices\n",
    "            praat_features[\"shimmer_local\"] = np.nan\n",
    "\n",
    "    except parselmouth.PraatError as e:\n",
    "        logger.error(f\"⚠️ PraatError processing {filename}: {e}. Storing NaNs.\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            f\"❌ Unexpected error during Praat processing for {filename}: {e}\"\n",
    "        )\n",
    "\n",
    "    return praat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:34:36.599006Z",
     "iopub.status.busy": "2025-04-23T15:34:36.598154Z",
     "iopub.status.idle": "2025-04-23T15:34:36.693596Z",
     "shell.execute_reply": "2025-04-23T15:34:36.692586Z",
     "shell.execute_reply.started": "2025-04-23T15:34:36.598974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"f0_median_praat\": 176.18724229901935,\n",
      "  \"jitter_local\": NaN,\n",
      "  \"jitter_local_abs\": 0.000111785,\n",
      "  \"jitter_rap\": NaN,\n",
      "  \"jitter_ppq5\": NaN,\n",
      "  \"shimmer_local\": NaN,\n",
      "  \"shimmer_local_db\": 1.211,\n",
      "  \"shimmer_apq3\": NaN,\n",
      "  \"shimmer_apq5\": NaN,\n",
      "  \"shimmer_apq11\": NaN\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "file_path = (\n",
    "    \"..\\\\..\\\\..\\\\data\\\\preprocessed_sample\\\\common_voice_en_1463_preprocessed.mp3\"\n",
    ")\n",
    "sound = parselmouth.Sound(file_path)\n",
    "\n",
    "\n",
    "# === Run extraction ===\n",
    "\n",
    "\n",
    "features = extract_praat_features(sound)\n",
    "\n",
    "\n",
    "# === Print output ===\n",
    "\n",
    "\n",
    "print(json.dumps(features, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:47:53.258732Z",
     "iopub.status.busy": "2025-04-23T15:47:53.258416Z",
     "iopub.status.idle": "2025-04-23T15:47:53.644727Z",
     "shell.execute_reply": "2025-04-23T15:47:53.643680Z",
     "shell.execute_reply.started": "2025-04-23T15:47:53.258708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Starting feature extraction test...\n",
      "[INFO] Starting feature extraction test...\n",
      "INFO:__main__:Starting feature extraction test...\n",
      "[INFO] Using test file: ..\\..\\..\\data\\preprocessed_sample\\common_voice_en_1463_preprocessed.mp3\n",
      "[INFO] Using test file: ..\\..\\..\\data\\preprocessed_sample\\common_voice_en_1463_preprocessed.mp3\n",
      "INFO:__main__:Using test file: ..\\..\\..\\data\\preprocessed_sample\\common_voice_en_1463_preprocessed.mp3\n",
      "[INFO] Loading audio: ..\\..\\..\\data\\preprocessed_sample\\common_voice_en_1463_preprocessed.mp3\n",
      "[INFO] Loading audio: ..\\..\\..\\data\\preprocessed_sample\\common_voice_en_1463_preprocessed.mp3\n",
      "INFO:__main__:Loading audio: ..\\..\\..\\data\\preprocessed_sample\\common_voice_en_1463_preprocessed.mp3\n",
      "[INFO] Audio loaded: 3.31s, sr=48000Hz\n",
      "[INFO] Audio loaded: 3.31s, sr=48000Hz\n",
      "INFO:__main__:Audio loaded: 3.31s, sr=48000Hz\n",
      "[INFO] Using adjusted parameters: fmax=8000, n_mels=80\n",
      "[INFO] Using adjusted parameters: fmax=8000, n_mels=80\n",
      "INFO:__main__:Using adjusted parameters: fmax=8000, n_mels=80\n",
      "[INFO] Feature extraction successful\n",
      "[INFO] Feature extraction successful\n",
      "INFO:__main__:Feature extraction successful\n",
      "[INFO] Feature extraction results:\n",
      "[INFO] Feature extraction results:\n",
      "INFO:__main__:Feature extraction results:\n",
      "[INFO] - mfcc: shape=(13, 311)\n",
      "[INFO] - mfcc: shape=(13, 311)\n",
      "INFO:__main__:- mfcc: shape=(13, 311)\n",
      "[INFO] - rms: shape=(1, 311)\n",
      "[INFO] - rms: shape=(1, 311)\n",
      "INFO:__main__:- rms: shape=(1, 311)\n",
      "[INFO] - spec_cent: shape=(1, 311)\n",
      "[INFO] - spec_cent: shape=(1, 311)\n",
      "INFO:__main__:- spec_cent: shape=(1, 311)\n",
      "[INFO] Test completed successfully\n",
      "[INFO] Test completed successfully\n",
      "INFO:__main__:Test completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mfcc', 'rms', 'spec_cent'])\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import logging\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "# Basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def extract_features(audio_path):\n",
    "    \"\"\"\n",
    "    Extract audio features with parameters adjusted to avoid mel filter issues\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Load the audio file\n",
    "        logger.info(f\"Loading audio: {audio_path}\")\n",
    "        y, sr = sf.read(audio_path)\n",
    "        logger.info(f\"Audio loaded: {len(y)/sr:.2f}s, sr={sr}Hz\")\n",
    "\n",
    "        # Step 2: Convert to mono if needed\n",
    "        if y.ndim > 1:\n",
    "            y = y.mean(axis=1)\n",
    "            logger.info(f\"Converted to mono: {len(y)} samples\")\n",
    "\n",
    "        # Step 3: Limit duration to first 5 seconds\n",
    "        max_samples = 5 * sr\n",
    "        if len(y) > max_samples:\n",
    "            y = y[:max_samples]\n",
    "            logger.info(f\"Trimmed to first 5 seconds: {len(y)} samples\")\n",
    "\n",
    "        # Step 4: Calculate suitable fmax based on sample rate\n",
    "        # The warning suggests adjusting fmax (maximum frequency)\n",
    "        # A common rule is to set fmax to sr/2.5 or lower\n",
    "        fmax = min(sr / 2.5, 8000)  # Cap at 8kHz which is usually enough for speech\n",
    "\n",
    "        # Step 5: Adjust n_mels based on sample rate\n",
    "        # Lower sample rates need fewer mel bands\n",
    "        if sr < 16000:\n",
    "            n_mels = 40  # Fewer mels for lower sample rates\n",
    "        elif sr < 22050:\n",
    "            n_mels = 64\n",
    "        else:\n",
    "            n_mels = 80  # Standard for higher sample rates\n",
    "\n",
    "        logger.info(f\"Using adjusted parameters: fmax={fmax}, n_mels={n_mels}\")\n",
    "\n",
    "        # Step 6: Extract features with the adjusted parameters\n",
    "        features = {}\n",
    "\n",
    "        # MFCC with adjusted parameters\n",
    "        features[\"mfcc\"] = librosa.feature.mfcc(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            n_mfcc=N_MFCC,\n",
    "            n_fft=N_FFT,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            fmax=fmax,\n",
    "            n_mels=n_mels,\n",
    "        )\n",
    "        gc.collect()\n",
    "\n",
    "        # RMS energy\n",
    "        features[\"rms\"] = librosa.feature.rms(\n",
    "            y=y, frame_length=N_FFT, hop_length=HOP_LENGTH\n",
    "        )\n",
    "        gc.collect()\n",
    "\n",
    "        # Spectral centroid with adjusted fmax\n",
    "        features[\"spec_cent\"] = librosa.feature.spectral_centroid(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            n_fft=N_FFT,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            freq=None,  # Let librosa calculate frequencies based on sr\n",
    "        )\n",
    "        gc.collect()\n",
    "\n",
    "        # Skip more memory-intensive features initially\n",
    "        # We can add them back one by one if this works\n",
    "\n",
    "        logger.info(\"Feature extraction successful\")\n",
    "        print(features.keys())\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during processing: {str(e)}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "def test_feature_extraction():\n",
    "    \"\"\"\n",
    "    Test function with better handling of audio files\n",
    "    \"\"\"\n",
    "    # Try to find an audio file\n",
    "    test_file = Path(\n",
    "        \"..\\\\..\\\\..\\\\data\\\\preprocessed_sample\\\\common_voice_en_1463_preprocessed.mp3\"\n",
    "    )\n",
    "\n",
    "    if not test_file.exists():\n",
    "        logger.warning(\n",
    "            f\"Test file {test_file} not found, searching for alternatives...\"\n",
    "        )\n",
    "\n",
    "        # Look in the kaggle input directory\n",
    "        kaggle_input = Path(\"..\\\\..\\\\..\\\\data\\\\preprocessed_sample\\\\\")\n",
    "        if kaggle_input.exists():\n",
    "            # Search for any audio file\n",
    "            for ext in [\".mp3\", \".wav\", \".flac\", \".ogg\"]:\n",
    "                for path in kaggle_input.glob(f\"**/*{ext}\"):\n",
    "                    logger.info(f\"Found alternative audio file: {path}\")\n",
    "                    test_file = path\n",
    "                    break\n",
    "\n",
    "                if test_file.exists() and test_file != Path(\n",
    "                    \"..\\\\..\\\\..\\\\data\\\\preprocessed_sample\\\\common_voice_en_100166_preprocessed.mp3\"\n",
    "                ):\n",
    "                    break\n",
    "\n",
    "    if test_file.exists():\n",
    "        logger.info(f\"Using test file: {test_file}\")\n",
    "        features = extract_features(test_file)\n",
    "\n",
    "        if features:\n",
    "            logger.info(\"Feature extraction results:\")\n",
    "            for name, feature in features.items():\n",
    "                logger.info(f\"- {name}: shape={feature.shape}\")\n",
    "        else:\n",
    "            logger.error(\"Feature extraction failed\")\n",
    "    else:\n",
    "        logger.error(\"No audio files found. Please upload a sample file.\")\n",
    "        # Create synthetic audio\n",
    "        logger.info(\"Creating synthetic audio for testing...\")\n",
    "        sr = 22050\n",
    "        duration = 2.0\n",
    "        t = np.linspace(0, duration, int(sr * duration))\n",
    "        y = 0.5 * np.sin(2 * np.pi * 440 * t)  # 440 Hz sine wave\n",
    "\n",
    "        # Save synthetic audio to a temporary file\n",
    "        output_file = Path(\n",
    "            \"..\\\\..\\\\..\\\\data\\\\preprocessed_sample\\\\common_voice_en_100166_synthesized.mp3\"\n",
    "        )\n",
    "        sf.write(output_file, y, sr)\n",
    "        logger.info(f\"Saved synthetic audio to {output_file}\")\n",
    "\n",
    "        # Try extraction on synthetic file\n",
    "        features = extract_features(output_file)\n",
    "\n",
    "        if features:\n",
    "            logger.info(\"Feature extraction on synthetic audio successful:\")\n",
    "            for name, feature in features.items():\n",
    "                logger.info(f\"- {name}: shape={feature.shape}\")\n",
    "        else:\n",
    "            logger.error(\"Feature extraction on synthetic audio failed\")\n",
    "\n",
    "\n",
    "# Run test with proper error handling\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        logger.info(\"Starting feature extraction test...\")\n",
    "        test_feature_extraction()\n",
    "        logger.info(\"Test completed successfully\")\n",
    "        print(\"done\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical error: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        print(\"failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-23T15:58:39.490Z",
     "iopub.execute_input": "2025-04-23T15:58:35.540596Z",
     "iopub.status.busy": "2025-04-23T15:58:35.539861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants for feature extraction (could be changed as needed)\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "N_MFCC = 13\n",
    "FMIN_PITCH_LIBROSA = 70.0\n",
    "FMAX_PITCH_LIBROSA = 400.0\n",
    "\n",
    "\n",
    "# Define feature extraction functions (as in the previous code)\n",
    "\n",
    "\n",
    "def extract_mfcc(y, sr):\n",
    "    return librosa.feature.mfcc(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mfcc=N_MFCC\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_rms(y):\n",
    "    return librosa.feature.rms(y=y, frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "\n",
    "\n",
    "def extract_spec_cent(y, sr):\n",
    "    return librosa.feature.spectral_centroid(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_spec_bw(y, sr):\n",
    "    return librosa.feature.spectral_bandwidth(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_spec_contrast(y, sr):\n",
    "    return librosa.feature.spectral_contrast(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_spec_flatness(y):\n",
    "    return librosa.feature.spectral_flatness(y=y, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "\n",
    "\n",
    "def extract_spec_rolloff(y, sr):\n",
    "    return librosa.feature.spectral_rolloff(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_zcr(y):\n",
    "    return librosa.feature.zero_crossing_rate(\n",
    "        y=y, frame_length=N_FFT, hop_length=HOP_LENGTH\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_pitch_librosa(y, sr):\n",
    "    f0, voiced_flag, _ = librosa.pyin(\n",
    "        y,\n",
    "        fmin=FMIN_PITCH_LIBROSA,\n",
    "        fmax=FMAX_PITCH_LIBROSA,\n",
    "        sr=sr,\n",
    "        frame_length=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "    )\n",
    "    return np.nan_to_num(f0, nan=0.0), voiced_flag\n",
    "\n",
    "\n",
    "def extract_librosa_features(y, sr):\n",
    "    try:\n",
    "        if len(y) < sr / 10:\n",
    "            logger.warning(\"⚠️ Audio too short for meaningful feature extraction\")\n",
    "            return None\n",
    "\n",
    "        features = {}\n",
    "        features[\"mfcc\"] = extract_mfcc(y, sr)\n",
    "        features[\"rms\"] = extract_rms(y)\n",
    "        features[\"spec_cent\"] = extract_spec_cent(y, sr)\n",
    "        features[\"spec_bw\"] = extract_spec_bw(y, sr)\n",
    "        features[\"spec_contrast\"] = extract_spec_contrast(y, sr)\n",
    "        features[\"spec_flatness\"] = extract_spec_flatness(y)\n",
    "        features[\"spec_rolloff\"] = extract_spec_rolloff(y, sr)\n",
    "        features[\"zcr\"] = extract_zcr(y)\n",
    "        features[\"pitch_librosa\"], features[\"voiced_flag\"] = extract_pitch_librosa(\n",
    "            y, sr\n",
    "        )\n",
    "\n",
    "        # Frame consistency alignment\n",
    "        try:\n",
    "            max_frames = max(\n",
    "                val.shape[1] if val.ndim > 1 else len(val)\n",
    "                for val in features.values()\n",
    "                if isinstance(val, np.ndarray)\n",
    "            )\n",
    "\n",
    "            for key, val in features.items():\n",
    "                if not isinstance(val, np.ndarray):\n",
    "                    continue\n",
    "\n",
    "                if val.ndim == 1:\n",
    "                    val_len = len(val)\n",
    "                    if val_len < max_frames:\n",
    "                        features[key] = np.pad(\n",
    "                            val, (0, max_frames - val_len), mode=\"edge\"\n",
    "                        )\n",
    "                    elif val_len > max_frames:\n",
    "                        features[key] = val[:max_frames]\n",
    "\n",
    "                elif val.ndim == 2:\n",
    "                    val_len = val.shape[1]\n",
    "                    if val_len < max_frames:\n",
    "                        features[key] = np.pad(\n",
    "                            val, ((0, 0), (0, max_frames - val_len)), mode=\"edge\"\n",
    "                        )\n",
    "                    elif val_len > max_frames:\n",
    "                        features[key] = val[:, :max_frames]\n",
    "\n",
    "        except ValueError as e:\n",
    "            logger.warning(f\"⚠️ Frame alignment issue: {e}\")\n",
    "\n",
    "        # Validate numerical stability\n",
    "        for key, val in features.items():\n",
    "            if isinstance(val, np.ndarray) and (\n",
    "                np.isnan(val).any() or np.isinf(val).any()\n",
    "            ):\n",
    "                logger.warning(f\"⚠️ NaN/Inf detected in {key}, replacing with zeros\")\n",
    "                features[key] = np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        return features\n",
    "\n",
    "    except MemoryError:\n",
    "        logger.error(\n",
    "            \"❌ MemoryError during Librosa feature extraction - possibly large input\"\n",
    "        )\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"❌ Unexpected error during Librosa feature extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Test with an example audio file\n",
    "def test_audio_features(audio_path):\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(\n",
    "            audio_file_path, sr=None, duration=30\n",
    "        )  # Only load the first 30 seconds\n",
    "\n",
    "        # Extract features\n",
    "        features = extract_librosa_features(y, sr)\n",
    "\n",
    "        # Display the features (for demonstration purposes)\n",
    "        if features:\n",
    "            print(\"Extracted Features:\")\n",
    "            for feature_name, feature_data in features.items():\n",
    "                print(\n",
    "                    f\"{feature_name}: {feature_data.shape if isinstance(feature_data, np.ndarray) else len(feature_data)}\"\n",
    "                )\n",
    "        else:\n",
    "            print(\"No features extracted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "# Test with a sample file (use a path to your audio file)\n",
    "audio_file_path = \"/kaggle/input/tiny-sample/common_voice_en_100168_preprocessed.mp3\"  # Replace with the path to your audio file\n",
    "test_audio_features(audio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T15:52:48.428460Z",
     "iopub.status.busy": "2025-04-23T15:52:48.427892Z",
     "iopub.status.idle": "2025-04-23T15:52:51.477744Z",
     "shell.execute_reply": "2025-04-23T15:52:51.476747Z",
     "shell.execute_reply.started": "2025-04-23T15:52:48.428426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def extract_librosa_features(y, sr):\n",
    "#     \"\"\"\n",
    "#     Extracts frame-wise features using Librosa.\n",
    "\n",
    "#     Args:\n",
    "#         y (np.ndarray): Audio time series.\n",
    "#         sr (int): Sample rate.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: Dictionary containing frame-wise librosa features. Returns None on failure.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         if len(y) < sr / 10:\n",
    "#             logger.warning(\"⚠️ Audio too short for meaningful feature extraction\")\n",
    "#             return None\n",
    "\n",
    "#         features = {\n",
    "#             \"mfcc\": librosa.feature.mfcc(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mfcc=N_MFCC),\n",
    "#             \"rms\": librosa.feature.rms(y=y, frame_length=N_FFT, hop_length=HOP_LENGTH),\n",
    "#             \"spec_cent\": librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH),\n",
    "#             \"spec_bw\": librosa.feature.spectral_bandwidth(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH),\n",
    "#             \"spec_contrast\": librosa.feature.spectral_contrast(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH),\n",
    "#             \"spec_flatness\": librosa.feature.spectral_flatness(y=y, n_fft=N_FFT, hop_length=HOP_LENGTH),\n",
    "#             \"spec_rolloff\": librosa.feature.spectral_rolloff(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH),\n",
    "#             \"zcr\": librosa.feature.zero_crossing_rate(y=y, frame_length=N_FFT, hop_length=HOP_LENGTH),\n",
    "#         }\n",
    "\n",
    "#         f0, voiced_flag, _ = librosa.pyin(\n",
    "#             y,\n",
    "#             fmin=FMIN_PITCH_LIBROSA,\n",
    "#             fmax=FMAX_PITCH_LIBROSA,\n",
    "#             sr=sr,\n",
    "#             frame_length=N_FFT,\n",
    "#             hop_length=HOP_LENGTH,\n",
    "#         )\n",
    "#         features[\"pitch_librosa\"] = np.nan_to_num(f0, nan=0.0)\n",
    "#         features[\"voiced_flag\"] = voiced_flag\n",
    "\n",
    "#         # Frame consistency alignment\n",
    "#         try:\n",
    "#             max_frames = max(\n",
    "#                 val.shape[1] if val.ndim > 1 else len(val)\n",
    "#                 for val in features.values()\n",
    "#                 if isinstance(val, np.ndarray)\n",
    "#             )\n",
    "\n",
    "#             for key, val in features.items():\n",
    "#                 if not isinstance(val, np.ndarray):\n",
    "#                     continue\n",
    "\n",
    "#                 if val.ndim == 1:\n",
    "#                     val_len = len(val)\n",
    "#                     if val_len < max_frames:\n",
    "#                         features[key] = np.pad(val, (0, max_frames - val_len), mode=\"edge\")\n",
    "#                     elif val_len > max_frames:\n",
    "#                         features[key] = val[:max_frames]\n",
    "\n",
    "#                 elif val.ndim == 2:\n",
    "#                     val_len = val.shape[1]\n",
    "#                     if val_len < max_frames:\n",
    "#                         features[key] = np.pad(val, ((0, 0), (0, max_frames - val_len)), mode=\"edge\")\n",
    "#                     elif val_len > max_frames:\n",
    "#                         features[key] = val[:, :max_frames]\n",
    "\n",
    "#         except ValueError as e:\n",
    "#             logger.warning(f\"⚠️ Frame alignment issue: {e}\")\n",
    "\n",
    "#         # Validate numerical stability\n",
    "#         for key, val in features.items():\n",
    "#             if isinstance(val, np.ndarray) and (np.isnan(val).any() or np.isinf(val).any()):\n",
    "#                 logger.warning(f\"⚠️ NaN/Inf detected in {key}, replacing with zeros\")\n",
    "#                 features[key] = np.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "#         return features\n",
    "\n",
    "#     except MemoryError:\n",
    "#         logger.error(\"❌ MemoryError during Librosa feature extraction - possibly large input\")\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         logger.exception(f\"❌ Unexpected error during Librosa feature extraction: {e}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_features(audio_path):\n",
    "    \"\"\"\n",
    "    Loads an audio file and extracts features using both Librosa and Parselmouth.\n",
    "\n",
    "    Args:\n",
    "        audio_path (str): Path to the preprocessed audio file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of feature names mapped to numpy arrays or scalars.\n",
    "              Returns None if loading or critical processing fails.\n",
    "    \"\"\"\n",
    "    all_features = {}\n",
    "    basename = os.path.basename(audio_path)\n",
    "\n",
    "    try:\n",
    "        # --- Librosa Extraction ---\n",
    "        try:\n",
    "            y, sr = librosa.load(audio_path, sr=SR)\n",
    "            if len(y) == 0:\n",
    "                logger.warning(f\"⚠️ Empty audio data in {basename}\")\n",
    "                return None\n",
    "\n",
    "            if np.isnan(y).any() or np.isinf(y).any():\n",
    "                logger.warning(\n",
    "                    f\"⚠️ NaN or Inf in audio data for {basename}, replacing with zeros\"\n",
    "                )\n",
    "                y = np.nan_to_num(y)\n",
    "\n",
    "            librosa_features = extract_librosa_features(y, sr)\n",
    "            if librosa_features:\n",
    "                all_features.update(librosa_features)\n",
    "                logger.info(f\"✅ Librosa features extracted for {basename}\")\n",
    "            else:\n",
    "                logger.warning(f\"⚠️ Failed to extract Librosa features for {basename}\")\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"❌ Librosa processing error for {basename}: {e}\")\n",
    "\n",
    "        # --- Parselmouth Extraction ---\n",
    "        try:\n",
    "            sound = parselmouth.Sound(audio_path)\n",
    "            sound.name = basename\n",
    "\n",
    "            praat_features = extract_praat_features(\n",
    "                sound, PRAAT_PITCH_FLOOR, PRAAT_PITCH_CEILING\n",
    "            )\n",
    "            all_features.update(praat_features)\n",
    "\n",
    "            if not all(np.isnan(v) for v in praat_features.values()):\n",
    "                logger.info(f\"✅ Praat features extracted for {basename}\")\n",
    "            else:\n",
    "                logger.warning(f\"⚠️ All Praat features are NaN for {basename}\")\n",
    "\n",
    "            del sound  # Free memory\n",
    "\n",
    "        except parselmouth.PraatError as e:\n",
    "            logger.error(f\"❌ PraatError processing {basename}: {e}\")\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"❌ Parselmouth processing error for {basename}: {e}\")\n",
    "\n",
    "        # Final check\n",
    "        if not all_features:\n",
    "            logger.error(f\"🛑 No features could be extracted for {basename}\")\n",
    "            return None\n",
    "\n",
    "        gc.collect()  # Free up memory\n",
    "        return all_features\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"❌ File not found: {audio_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"❌ Unexpected error processing {basename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_features(features, output_path):\n",
    "    \"\"\"\n",
    "    Saves the extracted features dictionary to a compressed .npz file.\n",
    "\n",
    "    Args:\n",
    "        features (dict): Dictionary of features to save.\n",
    "        output_path (str): Path to save the compressed .npz file.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if saved successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate feature contents\n",
    "        for key, value in features.items():\n",
    "            if isinstance(value, np.ndarray) and (\n",
    "                np.isnan(value).any() or np.isinf(value).any()\n",
    "            ):\n",
    "                logger.warning(\n",
    "                    f\"⚠️ Feature '{key}' contains NaN or Inf - replacing with zeros\"\n",
    "                )\n",
    "                features[key] = np.nan_to_num(value, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # Save to compressed .npz file\n",
    "        np.savez_compressed(output_path, **features)\n",
    "        logger.info(f\"✅ Features saved to {output_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"❌ Error saving features to {output_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_feature_wrapper(args):\n",
    "    \"\"\"\n",
    "    Wrapper function for multiprocessing that handles feature extraction and saving.\n",
    "\n",
    "    Args:\n",
    "        args (tuple): Tuple containing (filename, time_tracker, progress_lock).\n",
    "    \"\"\"\n",
    "    preprocessed_filename, time_tracker, progress_lock = args\n",
    "\n",
    "    input_path = os.path.join(PREPROCESSED_FOLDER, preprocessed_filename)\n",
    "    base_name = os.path.splitext(preprocessed_filename)[0]\n",
    "    original_name = base_name.replace(\n",
    "        \"_preprocessed\", \"\"\n",
    "    )  # Modify if naming convention changes\n",
    "    output_filename = f\"{original_name}_features.npz\"\n",
    "    output_path = os.path.join(FEATURE_FOLDER, output_filename)\n",
    "\n",
    "    # Skip if already processed (caching)\n",
    "    if os.path.exists(output_path):\n",
    "        with progress_lock:\n",
    "            time_tracker.update(\"skipped\")\n",
    "            if time_tracker.should_print_update():\n",
    "                logger.info(f\"⏩ {time_tracker.get_progress_str()}\")\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    features = extract_features(input_path)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    with progress_lock:\n",
    "        if features:\n",
    "            if save_features(features, output_path):\n",
    "                # time_tracker.update(\"completed\", elapsed)\n",
    "                logger.info(f\"✅ Processed {preprocessed_filename} in {elapsed:.1f}s\")\n",
    "            else:\n",
    "                # time_tracker.update(\"failed\")\n",
    "                logger.error(f\"❌ Failed to save features for {preprocessed_filename}\")\n",
    "        else:\n",
    "            # time_tracker.update(\"failed\")\n",
    "            logger.error(f\"🛑 Feature extraction failed for {preprocessed_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def tqdm_process_feature_wrapper(args_with_counter):\n",
    "#     \"\"\"Wrapper that processes a file and updates the progress counter for tqdm.\"\"\"\n",
    "#     args, counter, lock = args_with_counter\n",
    "#     try:\n",
    "#         result = process_feature_wrapper(args)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error processing {args[0]}: {e}\")\n",
    "#         result = None\n",
    "\n",
    "#     with lock:\n",
    "#         counter.value += 1\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "# def extract_features_for_all(input_folder, output_folder):\n",
    "#     \"\"\"Processes all compatible audio files using multiprocessing with comprehensive time tracking.\"\"\"\n",
    "#     try:\n",
    "#         os.makedirs(output_folder, exist_ok=True)\n",
    "#         logger.info(f\"Ensured output directory exists: {output_folder}\")\n",
    "#     except OSError as e:\n",
    "#         logger.error(f\"Error creating output directory {output_folder}: {e}\")\n",
    "#         return\n",
    "\n",
    "#     try:\n",
    "#         logger.info(f\"Searching for preprocessed files in: {input_folder}\")\n",
    "#         if not os.path.isdir(input_folder):\n",
    "#             raise FileNotFoundError(f\"Input directory not found: {input_folder}\")\n",
    "\n",
    "#         audio_extensions = (\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\")\n",
    "#         all_files = os.listdir(input_folder)\n",
    "#         preprocessed_files = [\n",
    "#             f\n",
    "#             for f in all_files\n",
    "#             if os.path.isfile(os.path.join(input_folder, f))\n",
    "#             and f.lower().endswith(audio_extensions)\n",
    "#         ]\n",
    "\n",
    "#         # Filter out zero-sized files\n",
    "#         valid_files = []\n",
    "#         for f in preprocessed_files:\n",
    "#             full_path = os.path.join(input_folder, f)\n",
    "#             if os.path.getsize(full_path) == 0:\n",
    "#                 logger.warning(f\"Skipping zero-sized file: {f}\")\n",
    "#                 continue\n",
    "#             valid_files.append(f)\n",
    "\n",
    "#         preprocessed_files = valid_files\n",
    "#         logger.info(f\"Found {len(preprocessed_files)} valid audio files.\")\n",
    "\n",
    "#     except FileNotFoundError as e:\n",
    "#         logger.error(f\"FileNotFoundError: {e}\")\n",
    "#         return\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error listing files in {input_folder}: {e}\")\n",
    "#         traceback.print_exc()\n",
    "#         return\n",
    "\n",
    "#     if not preprocessed_files:\n",
    "#         logger.info(f\"No compatible audio files found in {input_folder} to process.\")\n",
    "#         return\n",
    "\n",
    "#     # Setup multiprocessing and time tracking\n",
    "#     manager = Manager()\n",
    "#     progress_lock = manager.Lock()\n",
    "#     # time_tracker = TimeTracker(len(preprocessed_files))\n",
    "\n",
    "#     # Create shared counter for tqdm\n",
    "#     counter = manager.Value(\"i\", 0)\n",
    "#     tqdm_lock = manager.Lock()\n",
    "\n",
    "#     # Prepare process arguments with progress tracking\n",
    "#     original_args = [(filename, progress_lock) for filename in preprocessed_files]\n",
    "#     process_args = [(arg, counter, tqdm_lock) for arg in original_args]\n",
    "\n",
    "#     # Determine optimal number of workers\n",
    "#     num_processes = min(MAX_WORKERS, len(preprocessed_files))\n",
    "#     logger.info(f\"🚀 Starting feature extraction with {num_processes} processes...\")\n",
    "#     logger.info(\n",
    "#         f\"📊 Advanced progress tracking enabled - will show completion rate and ETA\"\n",
    "#     )\n",
    "\n",
    "#     try:\n",
    "#         # Create tqdm progress bar\n",
    "#         with tqdm(\n",
    "#             total=len(preprocessed_files), desc=\"🔄 Processing\", unit=\"file\", ncols=100\n",
    "#         ) as pbar:\n",
    "#             # Start processing with multiprocessing\n",
    "#             with Pool(processes=num_processes) as pool:\n",
    "#                 results = pool.map_async(tqdm_process_feature_wrapper, process_args)\n",
    "\n",
    "#                 # Update progress bar while waiting for results\n",
    "#                 while not results.ready():\n",
    "#                     completed = counter.value\n",
    "#                     pbar.n = completed\n",
    "#                     pbar.refresh()\n",
    "#                     time.sleep(0.1)\n",
    "\n",
    "#                 # Ensure progress bar is complete\n",
    "#                 pbar.n = len(preprocessed_files)\n",
    "#                 pbar.refresh()\n",
    "\n",
    "#     except KeyboardInterrupt:\n",
    "#         logger.warning(\n",
    "#             \"⚠️ Feature extraction interrupted by user. Some results may be incomplete.\"\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"❌ Error during multiprocessing: {e}\")\n",
    "#         traceback.print_exc()\n",
    "\n",
    "#     # Report final statistics\n",
    "#     logger.info(\"\\n📊 Feature Extraction Summary\")\n",
    "#     logger.info(\"=\" * 50)\n",
    "#     # logger.info(time_tracker.get_final_stats())\n",
    "#     logger.info(\"=\" * 50)\n",
    "\n",
    "#     # Validate results\n",
    "#     processed_files = [\n",
    "#         f for f in os.listdir(output_folder) if f.endswith(\"_features.npz\")\n",
    "#     ]\n",
    "#     success_rate = (\n",
    "#         len(processed_files) / len(preprocessed_files) if preprocessed_files else 0\n",
    "#     )\n",
    "#     logger.info(f\"Extracted features saved: {len(processed_files)} files\")\n",
    "#     logger.info(f\"Overall success rate: {success_rate:.1%}\")\n",
    "#     logger.info(f\"Feature extraction completed. Results are in: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the feature extraction process\n",
    "    extract_features_for_all(PREPROCESSED_FOLDER, FEATURE_FOLDER)\n",
    "    print(\"Feature extraction script completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7232067,
     "sourceId": 11530330,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
